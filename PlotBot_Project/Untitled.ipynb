{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import time\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/Users/jyj/Dropbox/A_A_Data_Analysis/Group_Projects\")\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions = api.search(q=\"@realDonaldTrump\")\n",
    "user_tweets = api.user_timeline(\"@realDonaldTrump\", count=100)\n",
    "print(len(mentions['statuses']))\n",
    "len(user_tweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "def update_twitter():\n",
    "\n",
    "    # Create dictionary to hold text and label entities\n",
    "    tweet_dict = {\"text\": [], \"label\": []}\n",
    "\n",
    "    mentions = api.search(q=\"@jamesji70232962 Analyze:\")\n",
    "    print(mentions)\n",
    "    words = []\n",
    "    try:\n",
    "        command = mentions[\"statuses\"][0][\"text\"]\n",
    "        words = command.split(\"Analyze:\")\n",
    "        target_account = words[1].strip()\n",
    "        print(f\"analysis for target_account: {target_account}\")\n",
    "        user_tweets = api.user_timeline(target_account, page=1)\n",
    "\n",
    "        # Loop through tweets\n",
    "        for tweet in user_tweets:\n",
    "\n",
    "            # Use nlp on each tweet\n",
    "            doc = nlp(tweet[\"text\"])\n",
    "\n",
    "            # Check if nlp returns no entities\n",
    "            if not doc.ents:\n",
    "                print(\"No entities to visualize\")\n",
    "                print(\"----------------------------\")\n",
    "            else:\n",
    "                # Print the entities for each doc\n",
    "                for ent in doc.ents:\n",
    "                    # Store entities in dictionary\n",
    "                    tweet_dict[\"text\"].append(ent.text)\n",
    "                    tweet_dict[\"label\"].append(ent.label_)\n",
    "        # Convert dictionary to DataFrame\n",
    "        tweet_df = pd.DataFrame(tweet_dict)\n",
    "        tweet_df.head()\n",
    "\n",
    "        # Group by labels# Group\n",
    "        label_frequency = tweet_df.groupby([\"label\"]).count()\n",
    "\n",
    "        # Get bar graph as a figure and tweet chart\n",
    "        bar = label_frequency.plot.bar()\n",
    "        fig = bar.get_figure()\n",
    "        fig.savefig(\"box.png\")\n",
    "        api.update_with_media(\n",
    "            \"box.png\", \"Break down of tweet labels for \" + target_account\n",
    "        )\n",
    "    except Exception:\n",
    "        raise\n",
    "\n",
    "    # Grab Self Tweets\n",
    "    tweets = api.user_timeline()\n",
    "\n",
    "    # Confirm the target account has never been tweeted before\n",
    "    repeat = False\n",
    "\n",
    "    for tweet in tweets:\n",
    "        if target_account in tweet[\"text\"]:\n",
    "            repeat = True\n",
    "            print(\"Sorry. Repeat detected!\")\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "# Have the Twitter bot update once a day for a week\n",
    "days = 0\n",
    "while days < 7:\n",
    "    print(f\"This is just daily Tweet # {days} to check-in. Have a nice day!\")\n",
    "\n",
    "    # Update the twitter\n",
    "    update_twitter()\n",
    "\n",
    "    # Wait a day\n",
    "    time.sleep(300)\n",
    "\n",
    "    # Update day counter\n",
    "    days += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
